cluster: "mkdir -p logs/{name} &&
  sbatch
  -J {name}
  -o logs/{name}/%j.out
  -e logs/{name}/%j.err
  --export ALL,OMP_NUM_THREADS={threads}
  --account MRC-BSU-SL2-CPU 
  --time {resources.runtime}
  --nodes 1
  --ntasks 1
  --cpus-per-task {threads}
  --mail-type FAIL
  --partition cclake,cclake-himem,skylake-himem,skylake
  --parsable"
# NB: We need the --parsable option to allow the cluster-status script cluster-cancel command to work 
jobs: 1000
local-cores: 4
cores: 12
keep-going: True
use-conda: True
scheduler: greedy
default-resources:
  - runtime=5
  - mem_mb=3420
  - tmpdir=tmp
resources:
  - concurrent_sans_permute_jobs=200
set-threads:
  - merge_randomised_simulated_sum_stats=12
  - prune_merged_randomised_simulated_sum_stats=12
  - process_combined_simgwas_sum_stats=12
  - calculate_theoretical_rg=1
  - permute_sim_pair=12
  - permute_trait_pair=12
set-resources:
  - merge_randomised_simulated_sum_stats:
      - runtime=25
  - prune_merged_randomised_simulated_sum_stats:
      - runtime=25
  - process_combined_simgwas_sum_stats:
      - runtime=25
group-components:
  - simulate=72
  - permutation=1
  - ldsc_hoeffding_sumher_gps_sans_permutation=1
  - calculate_theoretical_rg=1000
  - sumher=48
  - benchmark_naive_ecdf_algorithm=12
  - benchmark_fast_ecdf_algorithm=150
  - causal_variants=100
  - one_chrom_analysis=25
  - ukbb_ldsc=50
  - gps=50
rerun-incomplete: True
#rerun-triggers: 'mtime'
verbose: False
nolock: True
dry-run: False
notemp: False
max-status-checks-per-second: 10
latency-wait: 20
cluster-status: './cluster_status.py' 
cluster-cancel: 'scancel'
retries: 3
